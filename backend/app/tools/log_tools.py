from datetime import datetime
import re
import os
from collections import defaultdict, Counter

# è‡ªå‹•å–å¾— log æª”çš„çµ•å°è·¯å¾‘
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LOG_PATH = os.path.join(BASE_DIR, "../data/access_log_part2.log")

def filter_logs_by_time_and_status(start_time: str, end_time: str, status_code: str = None,
                                   http_method: str = None, source_ip: str = None):
    """
    å›å‚³ï¼š
        Tuple[str, list[str], dict]: çµ±è¨ˆè³‡è¨Šã€åŸå§‹ log lineã€çµæ§‹åŒ– table è³‡æ–™
    """

    time_format = "%d/%b/%Y:%H:%M:%S"

    try:
        start_dt = datetime.strptime(start_time, time_format)
        end_dt = datetime.strptime(end_time, time_format)
    except ValueError:
        print("æ™‚é–“æ ¼å¼éŒ¯èª¤")
        return "", [], {}

    # æ°¸é æ’é™¤ 2xx ç‹€æ…‹ç¢¼
    exclude_2xx = re.compile(r"^(?!2\d\d$)")

    # ç·¨è­¯ status_code æ­£è¦è¡¨é”å¼
    try:
        if status_code:
            user_status_pattern = re.compile(status_code)
            def combined_status_filter(code_str):
                return exclude_2xx.match(code_str) and user_status_pattern.match(code_str)
        else:
            def combined_status_filter(code_str):
                return exclude_2xx.match(code_str)
    except re.error:
        print(f"ç„¡æ•ˆçš„ status_code æ­£è¦è¡¨é”å¼ï¼š{status_code}")
        return "", [], {}

    # ç·¨è­¯ http_method æ­£è¦è¡¨é”å¼
    try:
        http_method_pattern = re.compile(http_method) if http_method else None
    except re.error:
        print(f"ç„¡æ•ˆçš„ http_method æ­£è¦è¡¨é”å¼ï¼š{http_method}")
        return "", [], {}

    # ç·¨è­¯ source_ip æ­£è¦è¡¨é”å¼
    try:
        source_ip_pattern = re.compile(source_ip) if source_ip else None
    except re.error:
        print(f"ç„¡æ•ˆçš„ source_ip æ­£è¦è¡¨é”å¼ï¼š{source_ip}")
        return "", [], {}

    filtered_logs = []
    structured_body = []

    # çµ±è¨ˆè³‡æ–™çµæ§‹
    ip_counter = Counter()
    status_counter = Counter()
    ip_to_resources = defaultdict(Counter)
    resource_counter = Counter()

    try:
        with open(LOG_PATH, 'r', encoding='utf-8') as f:
            for line in f:
                match = re.search(
                    r'\[(?P<time>.*?) \+\d{4}\] '
                    r'"(?P<method>[A-Z]+) (?P<resource>[^ ]+) HTTP/[^"]+" (?P<status>\d{3})',
                    line
                )
                if not match:
                    continue

                timestamp_str = match.group("time")
                method = match.group("method")
                resource = match.group("resource")
                log_status = int(match.group("status"))

                # å¾è¡Œå°¾å–ä¾†æº IP
                parts = line.strip().split()
                if len(parts) < 1:
                    continue
                real_ip = parts[-1]

                try:
                    log_dt = datetime.strptime(timestamp_str, time_format)
                except ValueError:
                    continue

                # æ¢ä»¶éæ¿¾
                if not (start_dt <= log_dt <= end_dt):
                    continue
                if not combined_status_filter(str(log_status)):
                    continue
                if http_method_pattern and not http_method_pattern.match(method):
                    continue
                if source_ip_pattern and not source_ip_pattern.match(real_ip):
                    continue

                filtered_logs.append(line.strip())

                structured_body.append({
                    "timestamp": timestamp_str,
                    "resource": resource,
                    "source_ip": real_ip,
                    "http_method": method,
                    "status_code": log_status
                })

                ip_counter[real_ip] += 1
                ip_to_resources[real_ip][resource] += 1
                resource_counter[resource] += 1
                status_counter[log_status] += 1

    except FileNotFoundError:
        print(f"æ‰¾ä¸åˆ° log æª”æ¡ˆï¼š{LOG_PATH}")
        return "", [], {}
    except Exception as e:
        print(f"è®€å– log æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return "", [], {}

    # çµ±è¨ˆè³‡è¨Šæ–‡å­—
    stats_summary = []

    stats_summary.append("ğŸ“Š å‰ 10 åè«‹æ±‚æ¬¡æ•¸æœ€å¤šçš„ IPï¼š")
    for ip, count in ip_counter.most_common(10):
        top_resources = ip_to_resources[ip].most_common(5)
        resources_str = ", ".join([f"{res} ({c}æ¬¡)" for res, c in top_resources])
        stats_summary.append(f"- IPï¼š{ip} | è«‹æ±‚æ¬¡æ•¸ï¼š{count} | è³‡æºï¼š{resources_str}")

    stats_summary.append("\nğŸ“Š å‰ 10 åè¢«è«‹æ±‚æœ€å¤šçš„è³‡æºï¼š")
    for resource, count in resource_counter.most_common(10):
        stats_summary.append(f"- è³‡æºï¼š{resource} | è«‹æ±‚æ¬¡æ•¸ï¼š{count}")
        
    stats_summary.append("\nğŸ“Š å„ç‹€æ…‹ç¢¼å‡ºç¾æ¬¡æ•¸ï¼š")
    for status, count in sorted(status_counter.items()):
        stats_summary.append(f"- ç‹€æ…‹ç¢¼ï¼š{status} | æ¬¡æ•¸ï¼š{count}")


    # çµæ§‹åŒ–è³‡æ–™æ ¼å¼ï¼ˆåƒ…å‰ 100 ç­†ï¼‰
    structured_table = {
        "type": "table",
        "data": {
            "headers": [
                {"key": "timestamp", "label": "æ™‚é–“"},
                {"key": "resource", "label": "è«‹æ±‚è³‡æº"},
                {"key": "source_ip", "label": "ä¾†æº IP"},
                {"key": "http_method", "label": "HTTP æ–¹æ³•"},
                {"key": "status_code", "label": "ç‹€æ…‹ç¢¼"},
            ],
            "body": structured_body[:100]
        }
    }

    return "\n".join(stats_summary), filtered_logs, structured_table
